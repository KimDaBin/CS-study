# 알고리즘
1. 알고리즘 분석
	1. 시간 복잡도와 공간복잡도
	2. 알고리즘의 정당성 증명
2. [알고리즘 설계 패러다임](#알고리즘-설계-패러다임)
	1. 완전 탐색
	2. [분할 정복](#분할-정복)
	3. [동적 계획법](#동적-계획법)
	4. 탐욕법
	5. 조합 탐색
	6. 최적화 문제 결정문제로 바꿔풀기
3. 유명한 알고리즘
	1. 수치해석
	2. 정수론
		1. 소수
		2. 유클리드 알고리즘
		3. 모듈라 연산
	3. 계산 기하
4. 기초 자료구조
	1. 비트마스크
	2. 부분 합
	3. 선형 자료 구조
	4. 큐와 스택, 데크
	5. 문자열
5. 트리
	1. 트리의 구현과 순회
	2. 이진 검색트리
	3. 우선순위 큐와 힙
	4. 구간 트리
	5. 상호 배타적 집합
	6. 트라이
6. [그래프](#그래프)
   1. [그래프의 표현과 정의](#그래프의-표현과-정의)
   2. [DFS](#DFS)
   3. [BFS](#BFS)
   4. [최단 경로 알고리즘](#최단-경로-알고리즘)
      1. [다익스트라](#다익스트라)
      2. 벨만-포드
      3. 플로이드의 모든 쌍 최단 거리 알고리즘
   5. 최소 스패닝 트리
      1. 크루스칼의 최소 스패닝 트리 알고리즘
      2. 프림의 최소 스패닝 트리 알고리즘
   6. 네트워크 유량
      1. 포드-풀커슨 알고리즘
      2. 네트워크 모델링
      3. 이분 매칭
7. 정렬


# 알고리즘 설계 패러다임
# 분할 정복
## 분할 정복(Divide and Conquer)이란?
한 문제를 둘 이상의 **부분 문제(sub-problem)** 로 나누어 해결하고 이를 합쳐 원래 문제를 해결하는 기법

분할 정복 알고리즘은 다음과 같이 세 부분으로 나누어서 생각해볼 수 있다.

1. **분할(Divide)** : 원래 문제를 분할하여 더 작은 하위 문제들 나눈다.

2. **정복(Conquer)** : 하위 문제 각각을 재귀적으로 해결

3. **병합(merge)** : 하위 문제들의 답을 합쳐서 원래 문제를 해결
 
<br>

분할 정복을 적용하기 위해서는 문제에 다음과 같은 몇 가지 특성이 성립해야 한다.

1. 부분 문제로 나누는 자연스러운 방법이 있어야 한다.

2. 부분 문제의 답을 조합해 원래 문제의 답을 계산하는 효율적인 방법이 있어야 한다.

   *(분할 정복을 사용한다고 무작정 효율이 좋아지는 것은 아니다.)*

<br>

## 분할 정복의 장/단점
- 장점 👍
  - 문제를 나눔으로써 어려운 문제를 해결할 수 있다는 장점이 있다. 그리고 이 방식이 그대로 사용되는 효율적인 알고리즘들도 여럿 있으며, 문제를 나누어 해결한다는 특징상 병렬적으로 문제를 해결하는 데 큰 강점이 있다.
  - 보통, 분할 정복의 경우 작은 문제로 분할함으로써 같은 작업을 더 빠르게 처리할 수 있게 해준다. (수행 시간 감소)

- 단점 👎
  - 함수를 재귀적으로 호출한다는 점에서 함수 호출로 인한 오버헤드가 발생하며, 스택에 다양한 데이터를 보관하고 있어야 하므로 스택 오버플로우가 발생하거나 과도한 메모리 사용을 하게 되는 단점이 있다.

<br>

## 일반적인 재귀 호출과 다른 점 

<p align="center">
<img src="https://user-images.githubusercontent.com/33649908/131237135-fd55bdac-c852-4681-b3f3-a6c4093fff28.png" width="50%">
</p>

* 분할 정복이 일반적인 재귀 호출과 다른 점은 **문제를 한 조각과 전체를 나누는 대신 거의 같은 크기의 부분 문제로 나누는 것** 이다.

* 보통 재귀 함수를 사용해서 분할 정복 알고리즘을 구현하지만, 분할 정복이라고 해서 반드시 재귀 함수를 이용하는 것은 아니다.

   함수 호출시 발생하는 오버헤드를 없애기 위해서 스택이나 큐 등을 이용하는 경우도 있다.

<br>

## 분할 정복 알고리즘 활용 예시

분할 정복이 쓰이는 예는 **이분검색, 병합정렬, 퀵정렬, 최대값 찾기, 임계값의 결정, 쉬트라센 행렬곱셈 알고리즘** 등이 있다.

<br>

### 병합 정렬과 퀵정렬 (같은 문제를 어느 단계에서 해결하느냐에 따른 구분)

병합 정렬(merge sort)과 퀵 정렬(quick sort)은 분할 정복 패러다임을 기반으로 해서 만들어진 대표적인 정렬 알고리즘이다.

이 두 알고리즘은 같은 아이디어로 정렬을 수행하지만 시간이 많이 걸리는 작업을 **분할 단계**에서 하느냐, **병합 단계**에서 하느냐가 다르다.

이렇게 같은 문제를 해결하는 알고리즘이더라도 어떤 식으로(어느 단계에서) 분할하느냐에 따라 다른 알고리즘이 될 수 있다.

<br>

### 병합 정렬

<p align="center">
<img src="https://user-images.githubusercontent.com/33649908/131238392-d6591d56-4690-48b0-83c9-7e027e2fcda4.png" width="40%">
</p>

* 전체 수행 시간은 **병합 과정**에 의해 지배된다.

* **O(n)** 시간이 걸리는 과정을 **재귀 호출 후에 진행** (병합 과정)

   문제의 수는 항상 절반으로 나눠지기 때문에 필요한 단계 수는 **O(logn)**

* 시간 복잡도 : 항상 **O(nlogn)** 으로 일정

<br>

### 퀵 정렬
<p align="center">
<img src="https://user-images.githubusercontent.com/33649908/131238476-bd4f5db7-48f1-41f2-bca7-f888cb02f133.png" height="200"> <img src="https://user-images.githubusercontent.com/33649908/131238219-42fd1206-d152-4924-bfa2-0f53e122fe58.png" height="200">
</p>

* 전체 수행 시간은 두개 부분 문제로 나누는 **파티션(partition) 과정**에 의해 지배된다. 분할된 두 부분 문제가 비슷한 크기로 비슷한 크기로 나눠진다는 보장이 없기 때문에, 이를 비슷한 크기로 나누는 좋은 기준을 선택하는 것은 퀵정렬에서 중요한 요소이다.

* **O(n)** 시간이 걸리는 과정을 **재귀 호출 전**에 진행 (분할)

   문제의 수가 항상 절반으로 나누어 진다는 보장이 없기 때문에 필요한 단계수를 정확히 계산하기 힘들다.
   
   **최악의 경우 n, 평균적인 경우 logn**만큼의 단계가 필요하다.

* 시간 복잡도 : 최악 = **O(n^2)**, 평균 = **O(nlogn)**

<br>

### 관련 문제
[백준 1629번 곱셈](https://www.acmicpc.net/problem/1629)

[백준 10830번 행렬 제곱](https://www.acmicpc.net/problem/10830)

<br>

# 동적 계획법
## 동적 계획법(Dynamic Programming, DP)이란?

동적 계획법은 주어진 문제를 풀기 위해서, 문제를 여러 개의 **하위 문제(subproblem)** 로 나누어 푼 다음, 그것을 결합하여 해결하는 방식이다.

<br>

<p align="center">
<img src="https://user-images.githubusercontent.com/33649908/131238559-1a8c7588-3713-475d-b740-69629b9b9fb4.png" width="50%">
</p>

동적 계획법은 처음 주어진 문제를 더 작은 문제들로 나눈 뒤 각 조각의 답을 계산하고, 이 답들로부터 원래 문제에 대한 답을 계산해 낸다는 점에서 분할 정복(Divide and Conquer)과 비슷하다. 하지만 가장 큰 차이점은 **동적 계획법에서는 쪼개진 작은 문제가 중복되지만, 분할 정복은 절대로 중복될수가 없다는 점**이다.

다시 말하면, 동적 계획법과 분할 정복의 차이는 **문제를 나누는 방식**이다. 동적 계획법에서는 어떤 부분 문제는 두 개 이상의 문제를 푸는데 사용될 수 있기 때문에, 이 문제의 답을 여러 번 계산하는 대신 **한 번만 계산하고 그 결과를 재활용함으로써 속도를 향상**시킬 수 있다. 이때 이미 계산한 값을 저장해 두는 메모리를 캐시(cache)라고 부르며, 두 번 이상 계산되는 부분 문제를 중복되는 **부분 문제(overlapping subproblems)** 라고 부른다.

<br>

* **동적 계획법의 조건**

   두 가지 속성을 만족해야 동적 계획법으로 문제를 풀 수 있다.

1. **Overlapping Subproblem**
   : 중복되는 부분 문제(overlapping subproblem) 는 어떤 문제가 여러 개의 부분 문제(subproblem)으로 쪼개질 수 있을 때 사용하는 용어이다. 이때 '부분 문제'란, 항상 새로운 부분 문제를 생성해내기 보다는 계속해서 같은 부분 문제가 여러 번 재사용되거나 재귀 알고리즘을 통해 해결되는 문제를 가리킨다.

2. **Optimal Substructure**
   : 최적 부분구조(optimal substructure)는 어떤 문제의 최적의 해결책이 그 부분 문제의 최적의 해결책으로 부터 설계될 수 있는 경우를 말한다. 즉, 최적 부분구조 일때 문제의 정답을 작은 문제의 정답에서부터 구할 수 있다. 이 속성은 동적 계획법이나 그리디 알고리즘의 유용성을 판별하는데 사용되기도 한다.
   
<br>

* **메모리제이션(Memorization)**

메모이제이션은 컴퓨터 프로그램이 동일한 계산을 반복해야 할 때, **이전에 계산한 값을 메모리에 저장함**으로써 동일한 계산의 반복 수행을 제거하여 **프로그램 실행 속도를 빠르게 하는 기술**이다. 동적 계획법의 핵심이 되는 기술이다.

동적 계획법에서 각 문제는 한 번만 풀어야 한다. (중복되는 부분 문제를 여러번 풀지 않는다는 뜻) Optimal Substructure를 만족하기 때문에 같은 문제는 구할 때마다 정답이 같다. 따라서 정답을 한 번 구했으면 그 정답을 캐시에 메모해놓는다. 이렇게 메모하는 것을 코드의 구현에서는 배열에 저장하는 것으로 할 수 있다. 이를 메모리제이션이라고 한다.

<br>

## 동적 계획법의 장/단점

- 장점 👍
  - 필요한 모든 가능성을 고려해서 구현하므로 항상 최적의 결과를 얻을 수 있다.
  
  - 메모리에 저장된 값을 사용하므로 큰 문제를 빠른 속도로 해결하여 최적의 해를 찾아낼 수 있다.

- 단점 👎
  - 모든 가능성에 대한 고려가 불충분할 경우 최적의 결과를 보장할 수 없다.
  
  - 다른 방법론에 비해 많은 메모리 공간을 요구한다.
  
<br>

## 동적 계획법의 구현 방법

동적 계획법의 구현 방식에는 두 가지 방법이 있다.

1. **Top-down** : 큰 문제를 작은 문제로 쪼개면서 푼다. **재귀**로 구현
2. **Bottom-up** : 작은 문제부터 차례대로 푼다. **반복문**으로 구현

Top-down과 Botton-up의 시간복잡도 차이는 문제에 따라 다를 수 있으므로 정확히 알 수는 없다. Top-down은 재귀 호출을 하기때문에 스택의 사용으로 시간이 더 걸릴 것이라고 생각할 수 있겠지만, 실제로 그 차이는 크지 않다. 

(다만, 파이썬의 경우 재귀 호출 시 스택 오버 플로우(stack overflow)가 발생할 수 있기 때문에, Bottom-up으로 구현하는 것이 좋다. C++과 Java에서는 재귀로 구현하는 것이 크게 문제가 되지 않는다.)

💡 Top-down으로만 해결가능하거나 Bottom-up으로만 해결가능한 문제는 극히 드문 경우이므로, 아무거나 선택해서 사용하면 된다.

<br>

## 동적 계획법의 활용 예시

동적 계획법의 예시로는 피보나치 수열 구하기, 이항계수 구하기, 최단경로의 플로이드 알고리즘, 최적화 문제, 외판원 문제 등이 있다.

<br>

### 관련 문제
[백준 2294번 동전2](https://www.acmicpc.net/problem/2294)

[백준 1463번 1로 만들기](https://www.acmicpc.net/problem/1463)

----

# 그래프
# 그래프의 표현과 정의
어떤 자료나 개념을 표현하는 정점(vertex)들의 집합 V와 이들을 연결하는 간선(edge)들의 집합 E로 구성된 자료구조

주로 현실 세계의 사물이나 추상적인 개념 간의 연결관계를 표현할 때 사용

## 그래프 관련 용어

- 노드 (Node): 위치를 말함, 정점(Vertex)라고도 함

- 간선 (Edge): 위치 간의 관계를 표시한 선으로 노드를 연결한 선이라고 보면 됨 (link 또는 branch 라고도 함)
- 인접 정점 (Adjacent Vertex) : 간선으로 직접 연결된 정점(또는 노드)
- 참고
  - 정점의 차수 (Degree): 무방향 그래프에서 하나의 정점에 인접한 정점의 수
  - 진입 차수 (In-Degree): 방향 그래프에서 외부에서 오는 간선의 수
  - 진출 차수 (Out-Degree): 방향 그래프에서 외부로 향하는 간선의 수
  - 경로 길이 (Path Length): 경로를 구성하기 위해 사용된 간선의 수
  - 단순 경로 (Simple Path): 처음 정점과 끝 정점을 제외하고 중복된 정점이 없는 경로
  - 사이클 (Cycle): 단순 경로의 시작 정점과 종료 정점이 동일한 경우

## 그래프의 종류

<img width="731" alt="그래프_종류" src="https://user-images.githubusercontent.com/16794320/127731827-67d5dabf-871b-4b8c-a150-07b1749593a8.png">

### 방향 그래프

그래프의 각 간선이 방향이라는 속성을 갖는 그래프

### 가중치 그래프

그래프의 각 간선이 가중치(weight)라는 송석을 갖는 그래프

### 다중 그래프

두 정점 사이에 두 개 이상의 간선이 있을 수 있는 그래프

### 트리

간선을 통해 두 정점을 잇는 방법이 딱 하나밖에 없는 그래프

### 이분그래프

그래프의 정점들을 겹치지 않는 두 개의 그룹으로 나눠서 서로 다른 그룹에 속한 정점들 사이에만 간선이 존재하도록 만들 수 있는 그래프

### DAG

사이클 없는 방향 그래프(Directed Acyclic Graph)

기본적으로 방향 그래프, 한 점에서 출발해 자기 자신으로 돌아오는 경로가 없는 경우

## 그래프의 경로

그래프에서 경로란 끝과 끝이 연결된 간선들을 순서대로 나열한 것
<img width="303" alt="그래프_경로" src="https://user-images.githubusercontent.com/16794320/127731829-9ac04786-3ff6-4711-b67f-0e3f7f12233c.png">

주어진 그림에서 1에서 5로 가는 경로는 
(1,2),(2,4),(4,5)와 같이 표현.
간단하게 1-2-4-5로도 표현

## 그래프의 표현 방법

V = 정점의 수

### 인접 리스트

그래프의 각 정점마다 해당 정점에서 나가는 간선의 목록을 저장해서 그래프를 표현

각 정점마다 하나의 연결 리스트를 갖는 방식으로 구현

### 인접 행렬

인접 리스트가 두 정점의 연결 관계를 확인하기위해 모든 리스트를 뒤져야한다는 단점 보완

|V|X|V| 크기의 행렬(|V|는 정점의 갯수)로 표현한다.

간**선의 수가 $V^2$에 비해서 훨씬 적은 경우 인접리스트를 사용하는 것이 유리하고**

**간선의 수가 $V^2$에 비례하는 경우 인접행렬을 사용하는 것이 유리하다.**

### 암시적 그래프 표현

그래프를 직접 메모리에 표현하지않고 그래프 구조만 사용하는 것이 유리한 경우

- 입력이 그래프의 형태를 띄지않는 문제의 경우(ex. 배열로 주어진 미로)
- 그래프의 크기가 아주 큰데 실제 사용하는 부분은 그래프의 일부분인 경우

# DFS

DFS(Depth-First Search,깊이 우선 탐색)은 그래프의 모든 노드를 탐색하는 가장 단순한 방법입니다.

정점의 자식들을 먼저 탐색하는 방식으로 다음의 순서를 따릅니다.

1. 현재 정점과 인접한 간선들을 하나씩 검사한다.
2. 아직 방문하지 않은 정점으로 향하는 간선이 있다면 그 간선을 따라간다.
3. 더 이상 갈 곳이 없는 막힌 정점에 도달할 때까지 반복한다.
4. 더이상 갈 곳이 없다면 가장 마지막에 지난 간선을 따라 돌아가 더 이상 방문할 정점이 없을 때까지 반복한다.

각 정점이 정수형인 경우를 예시로 설명하겠습니다.


![그래프_표](./img/graph_chart.png)

위와 같이 만들어진 그래프를 DFS로 탐색하는 그림은 다음과 같습니다.

<img src="./img/graph_DFS.png" alt="그래프_DFS" style="zoom:50%;" />


## Java로 그래프를 표현하는 방법

정점의 개수를 n, 간선의 개수를 m,  연결관계에 있는 노드를 (node1, node2)의 순서쌍으로 하면, 다음과 같이 그래프를 표현할 수 있습니다.

```java
Map<Integer, ArrayList<Integer>> graph = new TreeMap<Integer, ArrayList<Integer>>();
int n = 0, m = 0
Scanner sc = new Scanner(System.in);
n = sc.nextInt();
m = sc.nextInt();
//초기화 해줘야지 아래의 반복문에서 nullPointException 발생하지않는다.
for(int i = 0;i<n;i++){
  graph.put(i+1,new ArrayList<>());
}
for(int i = 0;i<m;i++){
  int n1 = 0, v1 = 0;
  node1 = sc.nextInt();
  node2 = sc.nextInt();
  graph.get(n1).add(node2);
  graph.get(node2).add(node1);
}
```



## DFS 알고리즘 구현

스택을 활용해서 구현할 수 있습니다.

```java
//code
public void dfsWithoutRecursion(int start) {
  Stack<Integer> stack = new Stack<Integer>();
  boolean[] isVisited = new boolean[adjVertices.size()];
  stack.push(start);
  while (!stack.isEmpty()) {
    int current = stack.pop();
    isVisited[current] = true;
    visit(current);
    for (int dest : adjVertices.get(current)) {
      if (!isVisited[dest])
        stack.push(dest);
    }
  }
}
```

재귀호출을 통해 메서드 스택을 이용해서 구현하는 방법도 있습니다.

```java
public void dfs(int start) {
  boolean[] isVisited = new boolean[adjVertices.size()];
  dfsRecursive(start, isVisited);
}
void dfsRecursive(int current, boolean[] isVisited) {
  isVisited[current] = true;
  visit(current);
  for (int dest : adjVertices.get(current)) {
    if (!isVisited[dest])
      dfsRecursive(dest, isVisited);
  }
}
```



## 시간 복잡도

일반적으로 DFS의 시간복잡도는 정점의 수를 V, 간선의 수를 E라고 할 때 O(V+E) 입니다.

# BFS

BFS(너비 우선 탐색)은 그래프를 탐색하는 방법 중 하나입니다.

정점들과 같은 레벨에 있는 노드(형제 노드)들을 먼저 탐색하는 방법으로 다음의 순서를 따릅니다. 

1. 현재 정점과 인접한 간선들을 하나씩 검사합니다.

2. 현재 노드에서 방문할 수 있는 노드를 전부 방문합니다.

3. 전부 방문한 후 그 다음 레벨의 노드를 방문합니다.

4. 더 이상 방문할 곳이 없다면 탐색을 종료합니다.

   

   ![그래프_표](./img/graph_chart.png)

<img src="./img/graph_BFS.png" alt="graph_BFS" style="zoom:50%;" />

## BFS 알고리즘 구현

queue와 배열을 이용해서 구현할 수 있습니다.

```java
//code
static void bfs(Map graph,int start_node){
  Queue<Integer> need_visit = new LinkedList<>();
  Queue<Integer> visited = new LinkedList<>();
  need_visit.add(start_node);

  while(need_visit.isEmpty()==false){
    int node = need_visit.poll();
    if(!visited.contains(node)){
      visited.add(node);
      ArrayList<Integer> temp = (ArrayList<Integer>) graph.get(node);
      for(int data : temp) need_visit.add(data);
    }
  }
  for(int data : visited)System.out.print(data+" ");
}
```



## 시간복잡도

일반적으로 BFS의 시간복잡도는 정점의 수를 V, 간선의 수를 E라고 할 때 O(V+E) 입니다.

# 최단 경로 알고리즘

### 최단 경로 문제란 무엇일까요?

최단 경로 문제란 두 노드를 잇난 가장 짧은 경로를 찾는 문제입니다. 즉, 가중치 그래프에서 간선의 가중치의 합이 최소가 되도록하는 경로를 찾는 것입니다.

그렇다면 최단 경로 문제는 어떤 종류가 있을까요??

1. 단일 출발 및 단일 도착 최단 경로 문제
2. 단일 출발 최단 경로 문제
3. 전체 쌍 최단 경로 문제

## 다익스트라

다익스트라 알고리즘은 최단 경로의 문제 종류 중 단일 출발 최단 경로 문제에 속합니다. 

그 이유는 다익스트라 알고리즘이 하나의 정점에서 다른 모든 정점 간의 가장 짧은 거리를 구하는 알고리즘이기 때문입니다.

### Basic idea

```java
//init
S = {v0}; distance[v0] = 0; 
for (w 가 V - S에 속한다면)//V-S는 전체 정점에서 이미 방문한 정점을 뺀 차집합.
	if ((v0, w)가 E에 속한다면) distance[w] = cost(v0,w); 
	else distance[w] = inf;

//algorithm
S = {v0};
while V–S != empty {
  //아래의 코드는 지금까지 최단 경로가 구해지지않은 정점 중 가장 가까운 거리를 반복한다는 의미
	u = min{distance[w], w 는 V-S의 원소};//---1
	
  S = S U {u}; 
  V–S = (V–S)–{u};
	for(vertex w : V–S)
		distance[w] = min{distance[w],distance[u]+cost(u,w)}//update distance[w];---2
}
```

위의 코드에서 1로 마킹한 부분에대한 설명을 하겠습니다.

먼저 length[v]는 최단 경로의 길이를 의미하고 distance[w]는 시작점에서부터의 최단 경로의 길이를 의미합니다.

S는 시작점을 포함해서 현재까지 최단 경로를 발견한 점들의 집합을 의미합니다.

<img src="./img/Dijkstra_0.png" alt="Dijkstra_0" style="zoom:75%;" />

u = min{distance[w], w 는 V-S의 원소}의 의미는 u까지의 최단 거리의 길이는 distance[u] 와 같다는 의미입니다. 

둘이 같다는 것은 다음처럼 증명할 수 있습니다.

![Dijkstra_1](./img/Dijkstra_1.png)

1. distance[u] > length[u]라고 가정해보겠습니다.
2. P를 시작점부터 u까지의 최단 경로라고 하면
3. P의 길이 = length[u]입니다.
4. P는 S에 속하지않는 최소 1개의 정점을 가집니다. 그렇지않다면 P의 길이 = distance[u]가 됩니다.
5. P의 경로에 속하면서 S에 속하지않는 시작점에서 가장 가까운 점을 w라 하겠습니다.
6. 그렇게 된다면 distance[u] > length[u] >= length[w] 가 성립하고, length[w] = distance[w]이기 때문에  이로부터
   **distance[u] > distance[w]**를 유추해낼 수 있습니다.
7. 이는 다익스트라 알고리즘은 아직 최단경로가 찾아지지않은 정점들만 선택한다는 정의에 어긋납니다.(지금 보는 점보다 가까운 경로가 존재한다면 이전 탐색에서 걸러져서 S에 포함되어있기 때문입니다.)

그렇기 때문에 distance[u] = length[u]입니다.

다음으로는 distance[w]를 업데이트하는 부분입니다.

<img src="./img/Dijkstra_2.png" alt="Dijkstra_2" style="zoom:50%;" />

위의 그림에서와 같이 시작점 v0에서 u를 거쳐 w로 가는 경로와 v0에서 w로 가는 경로의 길이 중 가까운 경로를 distance[w]로 설정하고 S와 V-S를 최신화해줍니다.

distance[ ]를 업데이트할 때 각각의 간선들이 2번씩 체크되는데 그 이유는 다음과 같습니다.

1. 

<img src="./img/Dijkstra_3.png" alt="Dijkstra_3" style="zoom:75%;" />

아직 최단 경로를 찾지 못한 정점 중 u에 인접한 정점들의 거리를 업데이트 할 때 u와 w를 연결하는 간선이 체크가 됩니다. 

2.

<img src="./img/Dijkstra_4.png" alt="Dijkstra_4" style="zoom:75%;" />

정점 w의 최단 경로가 찾아졌기 때문에, w는 S에 속하게됩니다. 아직 최단 경로를 찾기 못한 정점들에서 w까지의 거리를 업데이트하는 과정에서 u에서 w로의 간선이 다시 한 번 체크됩니다.



이런 방식으로 코드를 작성하면 각 정접들에대해서 u에 인접한 모든 간선을 살펴보는 연산이 추가되기 때문에 최악의 경우 시간복잡도가 O(𝑛^2)가 되버립니다. 이를 개선하는 방법으로는 대표적으로 우선순위 큐를 사용하는 방법(O( 𝑛 + 𝑚 log 𝑛))과 피보나치 힙을 사용하는 방법(O(𝑛 log 𝑛 + 𝑚))이 있습니다. 

피보나치 힙에대한 내용은 [피보나치 힙](https://en.wikipedia.org/wiki/Fibonacci_heap) 을 확인해주시고, 지금은 우선순위 큐에대한 내용을 다루겠습니다.

### 다익스트라 알고리즘 로직(우선순위 큐)

- 첫 번째 정점을 기준으로 연결되어있는 정점들을 추가해가면서 최단 거리를 갱신합니다.

  첫 정점부터 각 노드 사이의 거리를 저장하는 배열을 만든 후에 첫 정점의 인접 노드 간의 거리부터 먼저 계산하면서, 첫 정점부터 해당 노드 사이의 가장 짧은 거리를 해당 배열에 업데이트 합니다. 이런 로직은 현재의 정점에서 갈 수 있는 정점들부터 처리한다는 점에서 BFS와 비슷합니다. 

  다양한 다익스트라 알고리즘이 있지만 가장 개선된 형태인 우선순위 큐를 사용하는 방식을 다뤄보겠습니다.

  먼저 우선 순위 큐를 간단하게 설명하면 MinHeap 방식을 사용해서 현재 가장 짧은 거리를 가진 노드 정보를 먼저 꺼냅니다.

  꺼낸 노드는 다음의 과정을 반복합니다.

  1. 첫 정점을 기준으로 배열을 선언핸 첫 정점에서 각 정점까지의 거리를 저장합니다.
     - 초기에는 첫 정점의 거리를 0, 나머지는 무한대(inf)로 저장합니다.
     - 우선순위 큐에 순서쌍 (첫 정점, 거리 0) 만 먼저 넣어줍니다. 
  2. 우선순위 큐에서 노드를 꺼냅니다.
     - 처음에는 첫 정점만 저장된 상태이기때문에 첫번째 정점만 꺼내집니다.
     - 첫 정점에 인접한 노드들 각각에대해서 첫 정점에서 각 노드로 가는 거리와 현재 배열에 저장되어있는 첫 정점에서 각 정점까지의 거리를 비교합니다.
     - 배열에 저장되어 있는 거리보다, 첫 정점에서 해당 노드로 가는 거리가 더 짧은 경우, 배열에 해당 노드의 거리를 업데이트 합니다.
     - 배열에 해당 노드의 거리가 업데이트된 경우, 우선순위 큐에 해당 노드를 넣어줍니다.
  3. 2번의 과정을 우선순위 큐에서 꺼낼 노드가 없을 때까지 반복합니다.

- 우선순위 큐를 사용하면 지금까지 발견된 가장 짧은 거리의 노드에대해서 먼저 계산을 해서 더 긴 거리로 계산된 루트에 대해서는 계산을 스킵할 수 있다는 장점이 있습니다.

pseudo 코드는 다음과 같습니다. 

```java
found[], distance[]를 초기화
construct min_heap(V-{s});
for(i = 0; i < n-2; i++) { //𝑛−1iterations(=Θ(𝑛))---(1) 
  distance[u]가 최소인 정점 u를 선택합니다. //Θ(1) found[u] = T;로 바로 배열로 접근 가능
  min_heap에서 정점 u를 제거; //O(log𝑛)---(2)
  for(every vertex w adjacent to u) //Θ(𝑚)total---(a)
      if(found[w] == F && distance[u] + cost(u,w) < distance[w]){
        distance[w] = distance[u] + cost(u,w);
        adjust heap(w); //𝑂(log𝑛)foreachedgecheck---(b) 
  } // distance[w]가 수정됐기 때문에 heap을 조정해주는 for문
}
```



### 시간 복잡도

위의 pseudo code에서 다음 2가지 과정을 거칩니다.

(1),(a) - 각 정점마다 인접한 간선들을 모두 검사하는 과정 -> 𝑂(𝑛)

(2),(b) - 우선순위 큐에 정점/거리 정보를 넣고 삭제하는 과정 -> 𝑂(log𝑛)

따라서 전체 알고리즘은 O((𝑛+𝑚)log𝑛)입니다.

